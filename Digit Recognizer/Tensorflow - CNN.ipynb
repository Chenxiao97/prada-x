{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a Convolutional Neural Network (CNN) for the Digit Recognizer Kaggle competition found here: https://www.kaggle.com/c/digit-recognizer\n",
    "\n",
    "Notebook by Jonathan Gomez Martinez\n",
    "\n",
    "Used guide provided by TensorFlow here: https://www.tensorflow.org/get_started/mnist/pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the libraries neccessary for our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step in training is to get the data ready. We import the data, provided as a csv on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Import the provided training dataset\n",
    "rawtrain = pd.read_csv(\"train.csv\")\n",
    "\n",
    "#Choose an option below by placing/removing a \"#\"\n",
    "\n",
    "#rawin = rawtrain.iloc[:10000,] #Only keep some rows for development efficiency\n",
    "rawin = rawtrain  #Use all rows for improved accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow does not like the labels in the current format where 1 attribute holds the labels as an integer from 0-9. It prefers that each potential label be a binary choice within its own attribute. We will format it accordingly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\Anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "zeros = pd.DataFrame(np.zeros((len(rawin.index), 10)), columns=['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8',  'x9'])\n",
    "raw = pd.concat([zeros,rawin], axis =1)\n",
    "for i in raw.index:\n",
    "    j = raw.label[i]\n",
    "    raw[raw.columns[j]][i] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "start = time.time()\n",
    "for i in raw.index:\n",
    "    if raw.label[i] == 0:\n",
    "        raw.x0[i] = 1.0\n",
    "    elif raw.label[i] == 1:\n",
    "        raw.x1[i] = 1.0\n",
    "    elif raw.label[i] == 2:\n",
    "        raw.x2[i] = 1.0\n",
    "    elif raw.label[i] == 3:\n",
    "        raw.x3[i] = 1.0\n",
    "    elif raw.label[i] == 4:\n",
    "            raw.x4[i] = 1.0\n",
    "    elif raw.label[i] == 5:\n",
    "        raw.x5[i] = 1.0\n",
    "    elif raw.label[i] == 6:\n",
    "        raw.x6[i] = 1.0\n",
    "    elif raw.label[i] == 7:\n",
    "        raw.x7[i] = 1.0\n",
    "    elif raw.label[i] == 8:\n",
    "        raw.x8[i] = 1.0\n",
    "    elif raw.label[i] == 9:\n",
    "        raw.x9[i] = 1.0\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "For testing purposes, we need to seperate the data set into training and testing sets.\n",
    "We will also seperate the labels from the images in this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 33600 training digits and 8400 testing digits\n"
     ]
    }
   ],
   "source": [
    "test=raw.sample(frac=0.2,random_state=1251)\n",
    "train=raw.drop(test.index)\n",
    "l1 = len(train)\n",
    "l2 = len(test)\n",
    "print(\"Now we have\", l1, \"training digits and\", l2, \"testing digits\")\n",
    "#Seperate the drawn digits from the labels for both sets of data \n",
    "train_x = train.iloc[0:,11:]\n",
    "train_y = train.iloc[0:,:10]\n",
    "#len(train_x)\n",
    "#train_x.head()\n",
    "#train_y.head()\n",
    "test_x = test.iloc[0:,11:]\n",
    "test_y = test.iloc[0:,:10]\n",
    "test_labels = test.iloc[0:,10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally start to prepare our CNN. First step is to initialize a TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We start a tensorflow session named sess\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will initialize some weights and variables for our CNN to use in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Define some functions to simplify code later on\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) #Creates convolutional weight layer\n",
    "b_conv1 = bias_variable([32]) #Creates bias layer\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # Placeholder for input\n",
    "W = tf.Variable(tf.zeros([784, 10])) #Variable that transforms input after training \n",
    "b = tf.Variable(tf.zeros([10])) #Variable that transforms input after training\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b) #Loss function formula\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])  #Placeholder for output\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])) #Define cost function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) #Define training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a CNN is meant for images, we need to reshape the placeholder vector x into a 28 by 28 matrix, essentially taking our 1D arrays and returning them to the initial image state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create layers for our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#First Layer\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#Second Layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#Initialize layer variables\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next we define the cost function, training step, and measure of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we train the CNN. Since CNNs are resource heavy, we take subsets of the data and train in steps as opposed to running through the entire dataset. This also allows us to use a random sample each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iteration 0\n",
      "test accuracy on training 0.102381\n",
      "current iteration 50\n",
      "test accuracy on training 0.547619\n",
      "current iteration 100\n",
      "test accuracy on training 0.595238\n",
      "current iteration 150\n",
      "test accuracy on training 0.580952\n",
      "current iteration 200\n",
      "test accuracy on training 0.592857\n",
      "current iteration 250\n",
      "test accuracy on training 0.592857\n",
      "current iteration 300\n",
      "test accuracy on training 0.616667\n",
      "current iteration 350\n",
      "test accuracy on training 0.630952\n",
      "current iteration 400\n",
      "test accuracy on training 0.642857\n",
      "current iteration 450\n",
      "test accuracy on training 0.65\n",
      "current iteration 500\n",
      "test accuracy on training 0.657143\n",
      "current iteration 550\n",
      "test accuracy on training 0.652381\n",
      "current iteration 600\n",
      "test accuracy on training 0.685714\n",
      "current iteration 650\n",
      "test accuracy on training 0.647619\n",
      "current iteration 700\n",
      "test accuracy on training 0.628571\n",
      "current iteration 750\n",
      "test accuracy on training 0.628571\n",
      "current iteration 800\n",
      "test accuracy on training 0.652381\n",
      "current iteration 850\n",
      "test accuracy on training 0.642857\n",
      "current iteration 900\n",
      "test accuracy on training 0.666667\n",
      "current iteration 950\n",
      "test accuracy on training 0.669048\n",
      "current iteration 1000\n",
      "test accuracy on training 0.65\n",
      "current iteration 1050\n",
      "test accuracy on training 0.65\n",
      "current iteration 1100\n",
      "test accuracy on training 0.683333\n",
      "current iteration 1150\n",
      "test accuracy on training 0.683333\n",
      "current iteration 1200\n",
      "test accuracy on training 0.67619\n",
      "current iteration 1250\n",
      "test accuracy on training 0.719048\n",
      "current iteration 1300\n",
      "test accuracy on training 0.690476\n",
      "current iteration 1350\n",
      "test accuracy on training 0.709524\n",
      "current iteration 1400\n",
      "test accuracy on training 0.707143\n",
      "current iteration 1450\n",
      "test accuracy on training 0.740476\n",
      "current iteration 1500\n",
      "test accuracy on training 0.67381\n",
      "current iteration 1550\n",
      "test accuracy on training 0.695238\n",
      "current iteration 1600\n",
      "test accuracy on training 0.678571\n",
      "current iteration 1650\n",
      "test accuracy on training 0.709524\n",
      "current iteration 1700\n",
      "test accuracy on training 0.671429\n",
      "current iteration 1750\n",
      "test accuracy on training 0.704762\n",
      "current iteration 1800\n",
      "test accuracy on training 0.707143\n",
      "current iteration 1850\n",
      "test accuracy on training 0.719048\n",
      "current iteration 1900\n",
      "test accuracy on training 0.7\n",
      "current iteration 1950\n",
      "test accuracy on training 0.761905\n",
      "current iteration 2000\n",
      "test accuracy on training 0.745238\n",
      "current iteration 2050\n",
      "test accuracy on training 0.72619\n",
      "current iteration 2100\n",
      "test accuracy on training 0.728571\n",
      "current iteration 2150\n",
      "test accuracy on training 0.75\n",
      "current iteration 2200\n",
      "test accuracy on training 0.721429\n",
      "current iteration 2250\n",
      "test accuracy on training 0.7\n",
      "current iteration 2300\n",
      "test accuracy on training 0.711905\n",
      "current iteration 2350\n",
      "test accuracy on training 0.67619\n",
      "current iteration 2400\n",
      "test accuracy on training 0.721429\n",
      "current iteration 2450\n",
      "test accuracy on training 0.752381\n",
      "current iteration 2500\n",
      "test accuracy on training 0.761905\n",
      "current iteration 2550\n",
      "test accuracy on training 0.719048\n",
      "current iteration 2600\n",
      "test accuracy on training 0.742857\n",
      "current iteration 2650\n",
      "test accuracy on training 0.728571\n",
      "current iteration 2700\n",
      "test accuracy on training 0.719048\n",
      "current iteration 2750\n",
      "test accuracy on training 0.778571\n",
      "current iteration 2800\n",
      "test accuracy on training 0.757143\n",
      "current iteration 2850\n",
      "test accuracy on training 0.792857\n",
      "current iteration 2900\n",
      "test accuracy on training 0.761905\n",
      "current iteration 2950\n",
      "test accuracy on training 0.771429\n",
      "current iteration 3000\n",
      "test accuracy on training 0.77619\n",
      "current iteration 3050\n",
      "test accuracy on training 0.730952\n",
      "current iteration 3100\n",
      "test accuracy on training 0.769048\n",
      "current iteration 3150\n",
      "test accuracy on training 0.745238\n",
      "current iteration 3200\n",
      "test accuracy on training 0.757143\n",
      "current iteration 3250\n",
      "test accuracy on training 0.733333\n",
      "current iteration 3300\n",
      "test accuracy on training 0.761905\n",
      "current iteration 3350\n",
      "test accuracy on training 0.819048\n",
      "current iteration 3400\n",
      "test accuracy on training 0.783333\n",
      "current iteration 3450\n",
      "test accuracy on training 0.809524\n",
      "current iteration 3500\n",
      "test accuracy on training 0.792857\n",
      "current iteration 3550\n",
      "test accuracy on training 0.77619\n",
      "current iteration 3600\n",
      "test accuracy on training 0.816667\n",
      "current iteration 3650\n",
      "test accuracy on training 0.790476\n",
      "current iteration 3700\n",
      "test accuracy on training 0.778571\n",
      "current iteration 3750\n",
      "test accuracy on training 0.792857\n",
      "current iteration 3800\n",
      "test accuracy on training 0.802381\n",
      "current iteration 3850\n",
      "test accuracy on training 0.790476\n",
      "current iteration 3900\n",
      "test accuracy on training 0.804762\n",
      "current iteration 3950\n",
      "test accuracy on training 0.82619\n",
      "current iteration 4000\n",
      "test accuracy on training 0.828571\n",
      "current iteration 4050\n",
      "test accuracy on training 0.838095\n",
      "current iteration 4100\n",
      "test accuracy on training 0.814286\n",
      "current iteration 4150\n",
      "test accuracy on training 0.795238\n",
      "current iteration 4200\n",
      "test accuracy on training 0.783333\n",
      "current iteration 4250\n",
      "test accuracy on training 0.807143\n",
      "current iteration 4300\n",
      "test accuracy on training 0.85\n",
      "current iteration 4350\n",
      "test accuracy on training 0.861905\n",
      "current iteration 4400\n",
      "test accuracy on training 0.835714\n",
      "current iteration 4450\n",
      "test accuracy on training 0.819048\n",
      "current iteration 4500\n",
      "test accuracy on training 0.807143\n",
      "current iteration 4550\n",
      "test accuracy on training 0.830952\n",
      "current iteration 4600\n",
      "test accuracy on training 0.852381\n",
      "current iteration 4650\n",
      "test accuracy on training 0.82381\n",
      "current iteration 4700\n",
      "test accuracy on training 0.883333\n",
      "current iteration 4750\n",
      "test accuracy on training 0.857143\n",
      "current iteration 4800\n",
      "test accuracy on training 0.87619\n",
      "current iteration 4850\n",
      "test accuracy on training 0.859524\n",
      "current iteration 4900\n",
      "test accuracy on training 0.864286\n",
      "current iteration 4950\n",
      "test accuracy on training 0.857143\n",
      "current iteration 5000\n",
      "test accuracy on training 0.866667\n",
      "current iteration 5050\n",
      "test accuracy on training 0.859524\n",
      "current iteration 5100\n",
      "test accuracy on training 0.880952\n",
      "current iteration 5150\n",
      "test accuracy on training 0.830952\n",
      "current iteration 5200\n",
      "test accuracy on training 0.87619\n",
      "current iteration 5250\n",
      "test accuracy on training 0.892857\n",
      "current iteration 5300\n",
      "test accuracy on training 0.897619\n",
      "current iteration 5350\n",
      "test accuracy on training 0.904762\n",
      "current iteration 5400\n",
      "test accuracy on training 0.909524\n",
      "current iteration 5450\n",
      "test accuracy on training 0.866667\n",
      "current iteration 5500\n",
      "test accuracy on training 0.87381\n",
      "current iteration 5550\n",
      "test accuracy on training 0.928571\n",
      "current iteration 5600\n",
      "test accuracy on training 0.883333\n",
      "current iteration 5650\n",
      "test accuracy on training 0.883333\n",
      "current iteration 5700\n",
      "test accuracy on training 0.904762\n",
      "current iteration 5750\n",
      "test accuracy on training 0.911905\n",
      "current iteration 5800\n",
      "test accuracy on training 0.9\n",
      "current iteration 5850\n",
      "test accuracy on training 0.940476\n",
      "current iteration 5900\n",
      "test accuracy on training 0.914286\n",
      "current iteration 5950\n",
      "test accuracy on training 0.942857\n",
      "current iteration 6000\n",
      "test accuracy on training 0.942857\n",
      "current iteration 6050\n",
      "test accuracy on training 0.904762\n",
      "current iteration 6100\n",
      "test accuracy on training 0.940476\n",
      "current iteration 6150\n",
      "test accuracy on training 0.92381\n",
      "current iteration 6200\n",
      "test accuracy on training 0.909524\n",
      "current iteration 6250\n",
      "test accuracy on training 0.938095\n",
      "current iteration 6300\n",
      "test accuracy on training 0.914286\n",
      "current iteration 6350\n",
      "test accuracy on training 0.928571\n",
      "current iteration 6400\n",
      "test accuracy on training 0.904762\n",
      "current iteration 6450\n",
      "test accuracy on training 0.933333\n",
      "current iteration 6500\n",
      "test accuracy on training 0.938095\n",
      "current iteration 6550\n",
      "test accuracy on training 0.919048\n",
      "current iteration 6600\n",
      "test accuracy on training 0.933333\n",
      "current iteration 6650\n",
      "test accuracy on training 0.935714\n",
      "current iteration 6700\n",
      "test accuracy on training 0.940476\n",
      "current iteration 6750\n",
      "test accuracy on training 0.947619\n",
      "current iteration 6800\n",
      "test accuracy on training 0.942857\n",
      "current iteration 6850\n",
      "test accuracy on training 0.921429\n",
      "current iteration 6900\n",
      "test accuracy on training 0.945238\n",
      "current iteration 6950\n",
      "test accuracy on training 0.945238\n",
      "current iteration 7000\n",
      "test accuracy on training 0.945238\n",
      "current iteration 7050\n",
      "test accuracy on training 0.930952\n",
      "current iteration 7100\n",
      "test accuracy on training 0.945238\n",
      "current iteration 7150\n",
      "test accuracy on training 0.952381\n",
      "current iteration 7200\n",
      "test accuracy on training 0.919048\n",
      "current iteration 7250\n",
      "test accuracy on training 0.957143\n",
      "current iteration 7300\n",
      "test accuracy on training 0.935714\n",
      "current iteration 7350\n",
      "test accuracy on training 0.938095\n",
      "current iteration 7400\n",
      "test accuracy on training 0.957143\n",
      "current iteration 7450\n",
      "test accuracy on training 0.947619\n",
      "current iteration 7500\n",
      "test accuracy on training 0.959524\n",
      "current iteration 7550\n",
      "test accuracy on training 0.971429\n",
      "current iteration 7600\n",
      "test accuracy on training 0.966667\n",
      "current iteration 7650\n",
      "test accuracy on training 0.969048\n",
      "current iteration 7700\n",
      "test accuracy on training 0.954762\n",
      "current iteration 7750\n",
      "test accuracy on training 0.952381\n",
      "current iteration 7800\n",
      "test accuracy on training 0.940476\n",
      "current iteration 7850\n",
      "test accuracy on training 0.97381\n",
      "current iteration 7900\n",
      "test accuracy on training 0.957143\n",
      "current iteration 7950\n",
      "test accuracy on training 0.964286\n",
      "current iteration 8000\n",
      "test accuracy on training 0.959524\n",
      "current iteration 8050\n",
      "test accuracy on training 0.957143\n",
      "current iteration 8100\n",
      "test accuracy on training 0.957143\n",
      "current iteration 8150\n",
      "test accuracy on training 0.954762\n",
      "current iteration 8200\n",
      "test accuracy on training 0.969048\n",
      "current iteration 8250\n",
      "test accuracy on training 0.969048\n",
      "current iteration 8300\n",
      "test accuracy on training 0.945238\n",
      "current iteration 8350\n",
      "test accuracy on training 0.97619\n",
      "current iteration 8400\n",
      "test accuracy on training 0.952381\n",
      "current iteration 8450\n",
      "test accuracy on training 0.959524\n",
      "current iteration 8500\n",
      "test accuracy on training 0.964286\n",
      "current iteration 8550\n",
      "test accuracy on training 0.969048\n",
      "current iteration 8600\n",
      "test accuracy on training 0.940476\n",
      "current iteration 8650\n",
      "test accuracy on training 0.966667\n",
      "current iteration 8700\n",
      "test accuracy on training 0.964286\n",
      "current iteration 8750\n",
      "test accuracy on training 0.957143\n",
      "current iteration 8800\n",
      "test accuracy on training 0.964286\n",
      "current iteration 8850\n",
      "test accuracy on training 0.971429\n",
      "current iteration 8900\n",
      "test accuracy on training 0.969048\n",
      "current iteration 8950\n",
      "test accuracy on training 0.966667\n",
      "current iteration 9000\n",
      "test accuracy on training 0.952381\n",
      "current iteration 9050\n",
      "test accuracy on training 0.97381\n",
      "current iteration 9100\n",
      "test accuracy on training 0.980952\n",
      "current iteration 9150\n",
      "test accuracy on training 0.978571\n",
      "current iteration 9200\n",
      "test accuracy on training 0.964286\n",
      "current iteration 9250\n",
      "test accuracy on training 0.97619\n",
      "current iteration 9300\n",
      "test accuracy on training 0.969048\n",
      "current iteration 9350\n",
      "test accuracy on training 0.983333\n",
      "current iteration 9400\n",
      "test accuracy on training 0.980952\n",
      "current iteration 9450\n",
      "test accuracy on training 0.97381\n",
      "current iteration 9500\n",
      "test accuracy on training 0.983333\n",
      "current iteration 9550\n",
      "test accuracy on training 0.97619\n",
      "current iteration 9600\n",
      "test accuracy on training 0.969048\n",
      "current iteration 9650\n",
      "test accuracy on training 0.959524\n",
      "current iteration 9700\n",
      "test accuracy on training 0.97381\n",
      "current iteration 9750\n",
      "test accuracy on training 0.971429\n",
      "current iteration 9800\n",
      "test accuracy on training 0.957143\n",
      "current iteration 9850\n",
      "test accuracy on training 0.966667\n",
      "current iteration 9900\n",
      "test accuracy on training 0.983333\n",
      "current iteration 9950\n",
      "test accuracy on training 0.971429\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000): \n",
    "    t=train.sample(frac=0.0125) #Use 1.25% of training examples per iteration\n",
    "    ttrain_x = t.iloc[0:,11:] #Seperates labels from images\n",
    "    ttrain_y = t.iloc[0:,:10]\n",
    "    train_step.run(feed_dict={x: ttrain_x, y_: ttrain_y, keep_prob: 1}) #Train\n",
    "    if i%50 == 0: #Print metrics during training\n",
    "        print(\"current iteration \" + str(i))\n",
    "        print(\"test accuracy on training %g\"%accuracy.eval(feed_dict={\n",
    "            x: ttrain_x, y_: ttrain_y, keep_prob: .75}))\n",
    "#        print(\"test accuracy on testing %g\"%accuracy.eval(feed_dict={\n",
    "#            x: test_x, y_: test_y, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy on training 0.982381\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy on training %g\"%accuracy.eval(feed_dict={\n",
    "            x: test_x, y_: test_y, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the heavy resource use of a neural net, it is best practice to close the session and release resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
